import streamlit as st
import google.generativeai as genai
from PIL import Image

# 1. ç¶²é è¨­å®š
st.set_page_config(page_title="Honyen çš„æ—¥æœ¬å°éŠ", layout="wide")

# 2. è¨­å®š API Key
genai.configure(api_key="AIzaSyAShdl2lc8v7P8v1MfqYBcLnzovp3Sdi2Q")

# 3. å®šç¾©å°éŠå¤§è…¦ (åŒ…å« Google æœå°‹èˆ‡å°èˆªåŠŸèƒ½)
sys_prompt = """
ä½ æ˜¯ä¸€ä½ç²¾é€šæ—¥æœ¬æ—…éŠçš„å°ç£ç±å°éŠ Honyenã€‚
1. ä½ çš„ä»»å‹™æ˜¯ä»‹ç´¹æ—¥æœ¬æ™¯é»ã€ç¾é£Ÿï¼Œä¸¦è§£æ±ºäº¤é€šå•é¡Œã€‚
2. ã€é‡è¦ã€‘ä¸€å¾‹ä½¿ç”¨ã€Œç¹é«”ä¸­æ–‡ã€å›ç­”ã€‚
3. é‡åˆ°å°ˆæœ‰åè©è«‹æ¨™è¨»æ—¥æ–‡ï¼Œä¾‹å¦‚ï¼šè¶Šå…‰ç±³ (ã‚³ã‚·ãƒ’ã‚«ãƒª)ã€‚
4. èªæ°£ç†±æƒ…ã€å°ˆæ¥­ã€‚

5. ã€å°èˆªå°ˆå®¶æ¨¡å¼ã€‘ç•¶ä½¿ç”¨è€…å•è·¯æ™‚ï¼š
   - æä¾› Google Maps é€£çµï¼šhttp://googleusercontent.com/maps.google.com/maps?daddr={ç›®çš„åœ°}&travelmode=transit
   - åŒ…è£æˆ Markdownï¼šğŸ—ºï¸ [é»æ“Šé€™è£¡é–‹å•Ÿ Google Maps å°èˆª](ç¶²å€)

6. ã€æœå°‹å°å¹«æ‰‹ã€‘ç•¶éœ€è¦æ™‚åˆ»è¡¨æˆ–å®˜ç¶²æ™‚ï¼š
   - è«‹æä¾› Google æœå°‹é€£çµï¼šhttps://www.google.com/search?q={é—œéµå­—}
   - åŒ…è£æˆ Markdownï¼šğŸ” [é»æ“Šæœå°‹ç›¸é—œè³‡è¨Š](ç¶²å€)
"""

model = genai.GenerativeModel('gemini-2.5-flash', system_instruction=sys_prompt)

# --- ä»‹é¢è¨­è¨ˆé–‹å§‹ ---

st.title("ğŸ‡¯ğŸ‡µ Honyen çš„æ—¥æœ¬æ—…éŠ AI åŠ©ç†")
st.caption("æˆ‘æ˜¯ä½ çš„å°ˆå±¬å°éŠï¼Œè«‹ç›´æ¥åœ¨ä¸‹æ–¹è¼¸å…¥å•é¡Œï¼Œæˆ–æ˜¯æŒ‰æ‰‹æ©Ÿéµç›¤éº¥å…‹é¢¨èªéŸ³è¼¸å…¥ï¼")

# 4. ã€æ”¹è‰¯ã€‘ç…§ç‰‡ä¸Šå‚³å€ç§»åˆ°ä¸»ç•«é¢ (æ‰‹æ©Ÿæ›´å®¹æ˜“æŒ‰)
with st.expander("ğŸ“¸ ä¸Šå‚³ç…§ç‰‡ (é»æ“Šé€™è£¡å±•é–‹/æ”¶åˆ)"):
    uploaded_file = st.file_uploader("è«‹é¸æ“‡ç…§ç‰‡...", type=["jpg", "jpeg", "png"])
    image = None
    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        st.image(image, caption='å·²ä¸Šå‚³çš„ç…§ç‰‡', width=300) # æ‰‹æ©Ÿç‰ˆé™åˆ¶å¯¬åº¦æ¯”è¼ƒå¥½çœ‹

# 5. åˆå§‹åŒ–èŠå¤©ç´€éŒ„
if "messages" not in st.session_state:
    st.session_state.messages = []

# 6. é¡¯ç¤ºéå»çš„å°è©±ç´€éŒ„
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 7. èŠå¤©è¼¸å…¥æ¡†é‚è¼¯
if user_input := st.chat_input("è«‹è¼¸å…¥å•é¡Œ..."):
    
    # æ­¥é©Ÿ A: é¡¯ç¤ºä½¿ç”¨è€…çš„è©±
    st.chat_message("user").markdown(user_input)
    st.session_state.messages.append({"role": "user", "content": user_input})

    # æ­¥é©Ÿ B: ã€é—œéµä¿®å¾©ã€‘æŠŠéå»çš„å°è©±çµ„è£æˆã€Œè¨˜æ†¶åŒ…è£¹ã€
    # æˆ‘å€‘æŠŠä¹‹å‰çš„å°è©±ä¸²æˆä¸€å€‹é•·å­—ä¸²ï¼Œè®“ AI è®€éå†å›ç­”
    history_context = "é€™æ˜¯æˆ‘å€‘ä¹‹å‰çš„å°è©±ç´€éŒ„ï¼Œè«‹åƒè€ƒä¸Šä¸‹æ–‡å›ç­”ï¼š\n"
    for msg in st.session_state.messages[:-1]: # æ’é™¤æœ€æ–°çš„ä¸€å¥ï¼Œé¿å…é‡è¤‡
        role_name = "ä½¿ç”¨è€…" if msg["role"] == "user" else "å°éŠ"
        history_context += f"{role_name}: {msg['content']}\n"
    
    # çµ„åˆæœ€çµ‚çš„æç¤ºè© (Prompt)
    full_prompt = history_context + "\nä½¿ç”¨è€…ç¾åœ¨çš„å•é¡Œï¼š" + user_input

    # æ­¥é©Ÿ C: å‘¼å« AI å›ç­”
    with st.chat_message("assistant"):
        with st.spinner("å°éŠæ­£åœ¨å›æ†¶ä¸¦æ€è€ƒä¸­..."):
            try:
                # åˆ¤æ–·æœ‰æ²’æœ‰ç…§ç‰‡ (æœ‰ç…§ç‰‡æ™‚ï¼ŒåŒæ™‚å‚³é€ç…§ç‰‡ + é™„å¸¶è¨˜æ†¶çš„æ–‡å­—)
                if image:
                    response = model.generate_content([full_prompt, image])
                else:
                    response = model.generate_content(full_prompt)
                
                st.markdown(response.text)
                
                # æ­¥é©Ÿ D: æŠŠ AI çš„è©±å­˜é€²è¨˜æ†¶
                st.session_state.messages.append({"role": "assistant", "content": response.text})
                
            except Exception as e:
                st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")